


import os

# Get the project root directory
project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))

# Create directories for Ollama models
ollama_models_path = os.path.join(project_root, 'db_data', OLLAMA_models')
os.makedirs(ollama_models_path, exist_ok=True)

print(f"Created Ollama models directory at: {ollama_models_path}")

# Instead of creating a specific CodeLlama directory, we'll create a function to make model-specific directories as we need them.
def create_model_directory(model_name):
    model_path = os.path.join(ollama_models_path, model_name)
    os.makedirs(model_path, exist_ok=True)
    print(f"Created {model_name} directory at: {model_path}")






import os
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Ollama environment variables to append
ollama_env_vars = """
# Ollama Configuration
OLLAMA_MODELS_PATH=./db_data/ollama_models

# Ollama Configuration
OLLAMA_MODELS_PATH=./db_data/ollama_models

# CodeLlama Configuration
OLLAMA_CODESTRALL_CONTAINER_NAME=ragtools_ollama_codestral
OLLAMA_CODESTRALL_PORT=11435
OLLAMA_CODESTRALL_MODEL=sammcj/codestral-tweaked-22b
OLLAMA_CODESTRALL_PATH=../db_data/ollama_models/codestral
OLLAMA_CODESTRALL_GPU=0
OLLAMA_CODESTRALL_HOST=0.0.0.0

# Example of another model configuration (commented out)
# OLLAMA_LLAMA2_CONTAINER_NAME=ragtools_ollama_llama2
# OLLAMA_LLAMA2_PORT=11436
# OLLAMA_LLAMA2_MODEL=llama2
# OLLAMA_LLAMA2_PATH=./db_data/ollama_models/llama2
# OLLAMA_LLAMA2_GPU=1  # Assign to second GPU
"""

# Path to the .env file
env_file_path = os.path.join('..', '..', 'config', '.env')

try:
    # Check if file exists and is writable
    if os.path.exists(env_file_path):
        if os.access(env_file_path, os.W_OK):
            with open(env_file_path, 'a') as f:
                f.write(ollama_env_vars)
            logger.info(f"Successfully appended Ollama configurations to .env file at {env_file_path}")
        else:
            logger.error(f"The .env file at {env_file_path} is not writable.")
    else:
        logger.error(f".env file not found at {env_file_path}. Please create it first.")

except IOError as e:
    logger.error(f"An error occurred while writing to the .env file: {e}")

print("Ollama environment variable setup completed.")






ollama_service_config = """
    ollama_codestral:
        image: ollama/ollama
        container_name: ${OLLAMA_CODESTRALL_CONTAINER_NAME:-ragtools_ollama_codestral}
        environment:
            - OLLAMA_HOST=0.0.0.0:${OLLAMA_CODESTRALL_PORT:-11435}
        env_file:
            - .env
        ports:
            - ${OLLAMA_CODESTRALL_PORT:-11435}:${OLLAMA_CODESTRALL_PORT:-11435}
        volumes:
            - ../db_data/ollama_models:/root/.ollama
            - ../db_data/ollama_models/codestral:/root/.ollama/codestral
        entrypoint: ["ollama"]
        command: ["serve"]
        deploy:
            resources:
            reservations:
                devices:
                - driver: nvidia
                    count: 1
                    capabilities:
                    - gpu
        networks:
            - ragtools_network
"""

print("Ollama service configuration in docker-compose.yml:")
print(ollama_service_config)






import os

config_utils_path = os.path.join('..', 'src', 'utils', 'config_utils.py')

# Read the existing content
with open(config_utils_path, 'r') as f:
    existing_content = f.read()

# Define the new Ollama configurations
ollama_configs = '''
        # Ollama configurations
        self.OLLAMA_MODELS_PATH = os.getenv('OLLAMA_MODELS_PATH')
        
        # CodeStral Configuration
        self.OLLAMA_CODESTRALL_CONTAINER_NAME = os.getenv('OLLAMA_CODESTRALL_CONTAINER_NAME')
        self.OLLAMA_CODESTRALL_PORT = int(os.getenv('OLLAMA_CODESTRALL_PORT', 11435))
        self.OLLAMA_CODESTRALL_MODEL = os.getenv('OLLAMA_CODESTRALL_MODEL')
        self.OLLAMA_CODESTRALL_PATH = os.getenv('OLLAMA_CODESTRALL_PATH')
        self.OLLAMA_CODESTRALL_GPU = int(os.getenv('OLLAMA_CODESTRALL_GPU', 0))
        self.OLLAMA_CODESTRALL_HOST = os.getenv('OLLAMA_CODESTRALL_HOST')
'''

# Find the position to insert the new configurations
lines = existing_content.split('\n')
insert_line = -1
for i, line in enumerate(lines):
    if line.strip().startswith('def get_postgres_connection_params(self):'):
        insert_line = i
        break

if insert_line == -1:
    # If method not found, insert at the end of __init__
    for i, line in enumerate(reversed(lines)):
        if line.strip() == "self.DOCKER_NETWORK_NAME = os.getenv('DOCKER_NETWORK_NAME')":
            insert_line = len(lines) - i
            break

# Insert the new configurations
if insert_line != -1:
    updated_lines = lines[:insert_line] + ollama_configs.split('\n') + lines[insert_line:]
    updated_content = '\n'.join(updated_lines)
else:
    print("Could not find appropriate insertion point. Please update manually.")
    updated_content = existing_content

# Write the updated content back to the file
with open(config_utils_path, 'w') as f:
    f.write(updated_content)

print("Updated config_utils.py with Ollama configurations.")

# Optionally, print the updated Config class for verification
print("\nUpdated Config class:")
print(updated_content)







