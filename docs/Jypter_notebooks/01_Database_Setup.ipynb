{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Tools: Database Setup\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In this notebook, we'll set up Docker containers for our PostgreSQL database with pgvector extension and Neo4j graph database. We'll ensure both databases have accessible browser interfaces for easy management and are isolated in their own Docker network.\n",
    "\n",
    "## 2. Databases - PgVector and Neo4j\n",
    "\n",
    "\"We're using a combination of PgVector (PostgreSQL with vector extensions) and Neo4j to create a powerful RAG (Retrieval-Augmented Generation) system. PgVector allows us to store and efficiently query high-dimensional vectors, which are crucial for embedding-based search and similarity comparisons in machine learning applications.\n",
    "Neo4j, being a graph database, excels at representing and querying complex relationships between entities. By combining these two databases, we can create a system that not only understands semantic similarity (through vector embeddings) but also captures and leverages the intricate relationships between different pieces of information.\n",
    "This combination is particularly powerful for tasks like code analysis, where we need to understand both the content of code (which can be embedded into vectors) and the relationships between different code elements (which can be represented as a graph).\n",
    "\n",
    "## 3. Environment Configuration\n",
    "\n",
    "First, let's set up our environment variables. We'll create a file named `.env` in the `config/` directory:\n",
    "\n",
    "The .env file plays a crucial role in our framework as a centralized repository for environment-specific configuration variables. As we progress through our project, we'll continually add new variables to this file, allowing us to easily manage and update our configuration settings without modifying our code. The .env file stores sensitive information like database credentials, API keys, and other configuration parameters that may vary between development, testing, and production environments. To leverage these variables effectively, we've created the config_utils tool, which acts as an interface between our application and the .env file. The Config class within config_utils uses the python-dotenv library to load variables from the .env file, making them accessible throughout our application. This approach offers several advantages: it enhances security by keeping sensitive information out of our codebase, promotes flexibility by allowing easy configuration changes without code modifications, and improves maintainability by centralizing our configuration management. As we add new components or services to our framework, we'll update both the .env file and the Config class in config_utils, ensuring that our entire application remains in sync with our latest configuration needs.\n",
    "\n",
    "We have provided an example.env file located in config/ simply open it up in a text editor of your choice, update the passwords and save it as .env.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Docker Compose Configuration\n",
    "\n",
    "Let's examine and update our `docker-compose.yml` file. This configuration sets up our PostgreSQL and Neo4j databases in isolated containers with persistent storage.\n",
    "\n",
    "```yaml\n",
    "version: '3.8'\n",
    "\n",
    "services:\n",
    "  postgres:\n",
    "    container_name: ${POSTGRES_CONTAINER_NAME}\n",
    "    environment:\n",
    "      POSTGRES_DB: ${POSTGRES_DB}\n",
    "      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}\n",
    "      POSTGRES_USER: ${POSTGRES_USER}\n",
    "    image: ankane/pgvector\n",
    "    networks:\n",
    "    - ragtools_network\n",
    "    ports:\n",
    "    - ${POSTGRES_PORT}:5432\n",
    "    volumes:\n",
    "    - ../db_data/postgres:/var/lib/postgresql/data\n",
    "\n",
    "  neo4j:\n",
    "    image: neo4j:latest\n",
    "    container_name: ${NEO4J_CONTAINER_NAME}\n",
    "    environment:\n",
    "      NEO4J_AUTH: ${NEO4J_AUTH}\n",
    "    ports:\n",
    "      - \"${NEO4J_HTTP_PORT}:7474\"\n",
    "      - \"${NEO4J_BOLT_PORT}:7687\"\n",
    "    volumes:\n",
    "      - ../db_data/neo4j:/data\n",
    "    networks:\n",
    "      - ragtools_network\n",
    "\n",
    "networks:\n",
    "  ragtools_network:\n",
    "    name: ${DOCKER_NETWORK_NAME}\n",
    "\n",
    "```\n",
    "\n",
    "Let's break down the key components of this configuration:\n",
    "\n",
    "1. **Image Selection**: \n",
    "   - For PostgreSQL, we use the `ankane/pgvector` image, which comes with the pgvector extension pre-installed.\n",
    "   - For Neo4j, we use the latest official Neo4j image.\n",
    "\n",
    "2. **Environment Variables**: \n",
    "   - We use environment variables (${VAR_NAME}) to configure the containers. These variables are defined in our `.env` file.\n",
    "\n",
    "3. **Port Mapping**: \n",
    "   - We map the container ports to host ports, allowing access from the host machine.\n",
    "\n",
    "4. **Volumes**: \n",
    "   - For both PostgreSQL and Neo4j, we've updated the volume mappings to use the `db_data` directory:\n",
    "     - `../db_data/postgres:/var/lib/postgresql/data` for PostgreSQL\n",
    "     - `../db_data/neo4j:/data` for Neo4j\n",
    "   - This ensures that our data persists even if the containers are stopped or removed.\n",
    "\n",
    "5. **Networking**: \n",
    "   - Both containers are connected to a custom network named `ragtools_network`, isolating them from other Docker networks on the system.\n",
    "\n",
    "Now, let's create this `docker-compose.yml` file in our `config` directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# Get the current working directory (assuming we're in the notebook directory)\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the path to the config directory (two levels up from the notebook)\n",
    "config_dir = os.path.join(current_dir, '..', '..', 'config')\n",
    "\n",
    "# Ensure the config directory exists\n",
    "os.makedirs(config_dir, exist_ok=True)\n",
    "\n",
    "# Construct the full path for the docker-compose.yml file\n",
    "docker_compose_path = os.path.join(config_dir, 'docker-compose.yml')\n",
    "\n",
    "# Docker Compose configuration\n",
    "docker_compose_config = {\n",
    "    'version': '3.8',\n",
    "    'services': {\n",
    "        'postgres': {\n",
    "            'image': 'ankane/pgvector',\n",
    "            'container_name': '${POSTGRES_CONTAINER_NAME}',\n",
    "            'environment': {\n",
    "                'POSTGRES_DB': '${POSTGRES_DB}',\n",
    "                'POSTGRES_USER': '${POSTGRES_USER}',\n",
    "                'POSTGRES_PASSWORD': '${POSTGRES_PASSWORD}'\n",
    "            },\n",
    "            'ports': ['${POSTGRES_PORT}:5432'],\n",
    "            'volumes': ['../db_data/postgres:/var/lib/postgresql/data'],\n",
    "            'networks': ['ragtools_network']\n",
    "        },\n",
    "        'neo4j': {\n",
    "            'image': 'neo4j:latest',\n",
    "            'container_name': '${NEO4J_CONTAINER_NAME}',\n",
    "            'environment': {\n",
    "                'NEO4J_AUTH': '${NEO4J_AUTH}'\n",
    "            },\n",
    "            'ports': [\n",
    "                '${NEO4J_HTTP_PORT}:7474',\n",
    "                '${NEO4J_BOLT_PORT}:7687'\n",
    "            ],\n",
    "            'volumes': ['../db_data/neo4j:/data'],\n",
    "            'networks': ['ragtools_network']\n",
    "        }\n",
    "    },\n",
    "    'networks': {\n",
    "        'ragtools_network': {\n",
    "            'name': '${DOCKER_NETWORK_NAME}'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Write the Docker Compose configuration to the file\n",
    "with open(docker_compose_path, 'w') as f:\n",
    "    yaml.dump(docker_compose_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"docker-compose.yml file created at: {docker_compose_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This setup ensures that our PostgreSQL and Neo4j databases will store their data in the `db_data` directory, providing persistence across container restarts or removals. The `../db_data` path in the volume mappings is relative to the location of the `docker-compose.yml` file in the `config` directory, correctly pointing to the `db_data` directory at the project root.\n",
    "\n",
    "\n",
    "## 5. Configuration Utility\n",
    "\n",
    "To manage our configuration variables more efficiently, we'll create a `Config` class in a file named `config_utils.py`. This class will load environment variables from our `.env` file and provide easy access to these configurations throughout our project.\n",
    "\n",
    "Here's the content for the `config_utils.py` file:\n",
    "\n",
    "```python\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        \n",
    "        print(\"Debug: Environment variables loaded\")\n",
    "        for key, value in os.environ.items():\n",
    "            if key.startswith(('POSTGRES_', 'NEO4J_', 'DOCKER_')):\n",
    "                print(f\"Debug: {key} = {value}\")\n",
    "\n",
    "        # PostgreSQL configurations\n",
    "        self.POSTGRES_DB = os.getenv('POSTGRES_DB')\n",
    "        self.POSTGRES_USER = os.getenv('POSTGRES_USER')\n",
    "        self.POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "        self.POSTGRES_HOST = os.getenv('POSTGRES_HOST')\n",
    "        self.POSTGRES_PORT = os.getenv('POSTGRES_PORT')\n",
    "        \n",
    "        # Neo4j configurations\n",
    "        self.NEO4J_USER = os.getenv('NEO4J_USER', 'neo4j')\n",
    "        self.NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "        self.NEO4J_AUTH = os.getenv('NEO4J_AUTH')\n",
    "        if not self.NEO4J_AUTH:\n",
    "            self.NEO4J_AUTH = f\"{self.NEO4J_USER}/{self.NEO4J_PASSWORD}\"\n",
    "        self.NEO4J_HOST = os.getenv('NEO4J_HOST', 'localhost')\n",
    "        self.NEO4J_HTTP_PORT = os.getenv('NEO4J_HTTP_PORT', '7474')\n",
    "        self.NEO4J_BOLT_PORT = os.getenv('NEO4J_BOLT_PORT', '7687')\n",
    "        \n",
    "        # Docker configurations\n",
    "        self.POSTGRES_CONTAINER_NAME = os.getenv('POSTGRES_CONTAINER_NAME')\n",
    "        self.NEO4J_CONTAINER_NAME = os.getenv('NEO4J_CONTAINER_NAME')\n",
    "        self.DOCKER_NETWORK_NAME = os.getenv('DOCKER_NETWORK_NAME')\n",
    "\n",
    "        print(\"Debug: Config object initialized\")\n",
    "        self.print_all_attributes()\n",
    "\n",
    "    def get_neo4j_connection_params(self):\n",
    "        user, password = self.NEO4J_AUTH.split('/')\n",
    "        return {\n",
    "            \"uri\": f\"bolt://{self.NEO4J_HOST}:{self.NEO4J_BOLT_PORT}\",\n",
    "            \"auth\": (user, password)\n",
    "        }\n",
    "\n",
    "    def get_postgres_connection_params(self):\n",
    "        return {\n",
    "            \"dbname\": self.POSTGRES_DB,\n",
    "            \"user\": self.POSTGRES_USER,\n",
    "            \"password\": self.POSTGRES_PASSWORD,\n",
    "            \"host\": self.POSTGRES_HOST,\n",
    "            \"port\": self.POSTGRES_PORT\n",
    "        }\n",
    "\n",
    "    def print_all_attributes(self):\n",
    "        print(\"All Config attributes:\")\n",
    "        for attr, value in self.__dict__.items():\n",
    "            print(f\"{attr}: {value}\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_env(cls, env_path):\n",
    "        # Load environment variables from a specific .env file\n",
    "        load_dotenv(dotenv_path=env_path)\n",
    "        return cls()\n",
    "\n",
    "    def update_from_dict(self, config_dict):\n",
    "        # Update configuration from a dictionary\n",
    "        for key, value in config_dict.items():\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "    def to_dict(self):\n",
    "        # Convert configuration to a dictionary\n",
    "        return {k: v for k, v in self.__dict__.items() if not k.startswith('_')}\n",
    "```\n",
    "\n",
    "now lets put that file in place with the next code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the path to the src/utils directory\n",
    "utils_dir = os.path.join(current_dir, '..', '..', 'src', 'utils')\n",
    "\n",
    "# Ensure the utils directory exists\n",
    "os.makedirs(utils_dir, exist_ok=True)\n",
    "\n",
    "# Construct the full path for the config_utils.py file\n",
    "config_utils_path = os.path.join(utils_dir, 'config_utils.py')\n",
    "\n",
    "# Updated content of the config_utils.py file\n",
    "config_utils_content = '''\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        load_dotenv()\n",
    "        \n",
    "        print(\"Debug: Environment variables loaded\")\n",
    "        for key, value in os.environ.items():\n",
    "            if key.startswith(('POSTGRES_', 'NEO4J_', 'DOCKER_')):\n",
    "                print(f\"Debug: {key} = {value}\")\n",
    "\n",
    "        # PostgreSQL configurations\n",
    "        self.POSTGRES_DB = os.getenv('POSTGRES_DB')\n",
    "        self.POSTGRES_USER = os.getenv('POSTGRES_USER')\n",
    "        self.POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD')\n",
    "        self.POSTGRES_HOST = os.getenv('POSTGRES_HOST')\n",
    "        self.POSTGRES_PORT = os.getenv('POSTGRES_PORT')\n",
    "        \n",
    "        # Neo4j configurations\n",
    "        self.NEO4J_USER = os.getenv('NEO4J_USER', 'neo4j')\n",
    "        self.NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "        self.NEO4J_AUTH = os.getenv('NEO4J_AUTH')\n",
    "        if not self.NEO4J_AUTH:\n",
    "            self.NEO4J_AUTH = f\"{self.NEO4J_USER}/{self.NEO4J_PASSWORD}\"\n",
    "        self.NEO4J_HOST = os.getenv('NEO4J_HOST', 'localhost')\n",
    "        self.NEO4J_HTTP_PORT = os.getenv('NEO4J_HTTP_PORT', '7474')\n",
    "        self.NEO4J_BOLT_PORT = os.getenv('NEO4J_BOLT_PORT', '7687')\n",
    "        \n",
    "        # Docker configurations\n",
    "        self.POSTGRES_CONTAINER_NAME = os.getenv('POSTGRES_CONTAINER_NAME')\n",
    "        self.NEO4J_CONTAINER_NAME = os.getenv('NEO4J_CONTAINER_NAME')\n",
    "        self.DOCKER_NETWORK_NAME = os.getenv('DOCKER_NETWORK_NAME')\n",
    "\n",
    "        print(\"Debug: Config object initialized\")\n",
    "        self.print_all_attributes()\n",
    "\n",
    "    def get_neo4j_connection_params(self):\n",
    "        user, password = self.NEO4J_AUTH.split('/')\n",
    "        return {\n",
    "            \"uri\": f\"bolt://{self.NEO4J_HOST}:{self.NEO4J_BOLT_PORT}\",\n",
    "            \"auth\": (user, password)\n",
    "        }\n",
    "\n",
    "    def get_postgres_connection_params(self):\n",
    "        return {\n",
    "            \"dbname\": self.POSTGRES_DB,\n",
    "            \"user\": self.POSTGRES_USER,\n",
    "            \"password\": self.POSTGRES_PASSWORD,\n",
    "            \"host\": self.POSTGRES_HOST,\n",
    "            \"port\": self.POSTGRES_PORT\n",
    "        }\n",
    "\n",
    "    def print_all_attributes(self):\n",
    "        print(\"All Config attributes:\")\n",
    "        for attr, value in self.__dict__.items():\n",
    "            print(f\"{attr}: {value}\")\n",
    "\n",
    "    @classmethod\n",
    "    def from_env(cls, env_path):\n",
    "        # Load environment variables from a specific .env file\n",
    "        load_dotenv(dotenv_path=env_path)\n",
    "        return cls()\n",
    "\n",
    "    def update_from_dict(self, config_dict):\n",
    "        # Update configuration from a dictionary\n",
    "        for key, value in config_dict.items():\n",
    "            if hasattr(self, key):\n",
    "                setattr(self, key, value)\n",
    "\n",
    "    def to_dict(self):\n",
    "        # Convert configuration to a dictionary\n",
    "        return {k: v for k, v in self.__dict__.items() if not k.startswith('_')}\n",
    "'''\n",
    "\n",
    "# Write the content to the config_utils.py file\n",
    "with open(config_utils_path, 'w') as f:\n",
    "    f.write(config_utils_content)\n",
    "\n",
    "print(f\"Updated config_utils.py file created at: {config_utils_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `Config` class provides a centralized way to access our configuration variables. It loads the environment variables from the `.env` file and stores them as attributes. It also includes methods to easily retrieve connection parameters for our databases, update configurations, and convert to/from dictionary format for flexibility.\n",
    "\n",
    "Key features of this Config class:\n",
    "\n",
    "1. **Environment Variable Loading**: Uses `load_dotenv()` to load variables from the .env file.\n",
    "2. **Flexible Configuration**: Includes methods to load from specific .env files, update from dictionaries, and convert to dictionaries.\n",
    "3. **Connection Parameters**: Provides methods to get formatted connection parameters for both PostgreSQL and Neo4j.\n",
    "4. **Debugging**: Includes a `print_all_attributes` method for easy configuration verification.\n",
    "\n",
    "This design allows for easy extension as the project grows. New configuration parameters can be added to the `__init__` method, and new methods can be created for additional services or features.\n",
    "\n",
    "To use this Config class in other parts of your project, you can import it like this:\n",
    "\n",
    "```python\n",
    "from src.utils.config_utils import Config\n",
    "\n",
    "config = Config()\n",
    "postgres_params = config.get_postgres_connection_params()\n",
    "neo4j_params = config.get_neo4j_connection_params()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create DockerComposeManager\n",
    "\n",
    "In the future, we may want automation to spin up a Docker environment, so let's create a Python tool to help us manage that. DockerComposeManager will be that utility.\n",
    "\n",
    "```python\n",
    "import subprocess\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class DockerComposeManager:\n",
    "    def __init__(self, compose_file_path):\n",
    "        self.compose_file_path = os.path.abspath(compose_file_path)\n",
    "        load_dotenv(dotenv_path=os.path.join(os.path.dirname(self.compose_file_path), '.env'))\n",
    "\n",
    "    def run_command(self, command):\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                f\"docker compose -f {self.compose_file_path} {command}\",\n",
    "                shell=True, check=True, capture_output=True, text=True\n",
    "            )\n",
    "            print(result.stdout)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing command: {e}\")\n",
    "            print(e.stderr)\n",
    "\n",
    "    def start_containers(self):\n",
    "        self.run_command(\"up -d\")\n",
    "\n",
    "    def stop_containers(self):\n",
    "        self.run_command(\"down\")\n",
    "\n",
    "    def show_container_status(self):\n",
    "        self.run_command(\"ps\")\n",
    "```\n",
    "\n",
    "Let's discuss this code and its significance in our project:\n",
    "\n",
    "1. **Early Standardization**: By implementing this class now, we're setting a standard for how Docker operations will be handled throughout the project. This consistency will be invaluable as the project grows and more developers potentially join.\n",
    "\n",
    "2. **Abstraction of Docker Commands**: The class abstracts Docker Compose commands into simple method calls. This abstraction makes it easier for team members who might not be Docker experts to manage containers.\n",
    "\n",
    "3. **Error Handling and Logging**: The `run_command` method includes error handling, which will help catch and report issues early in the development process. This can be crucial for troubleshooting complex multi-container setups.\n",
    "\n",
    "4. **Environment Variable Integration**: The class loads environment variables from the .env file, ensuring that our Docker operations are always using the correct configuration.\n",
    "\n",
    "5. **Flexibility for Future Expansion**: While we currently only have methods for starting, stopping, and checking status, the structure allows easy addition of more complex operations in the future.\n",
    "\n",
    "6. **Testing and Development Aid**: This class will be incredibly useful for setting up and tearing down test environments. Developers can easily spin up the entire stack or individual services as needed.\n",
    "\n",
    "7. **Troubleshooting Tool**: The `show_container_status` method provides a quick way to check on the state of our Docker environment, which can be invaluable during development and debugging.\n",
    "\n",
    "8. **Potential for CI/CD Integration**: As the project evolves, this class could be easily integrated into CI/CD pipelines for automated testing and deployment.\n",
    "\n",
    "9. **Learning Opportunity**: This class serves as an excellent example of how to create utility classes that bridge application code with system operations, a valuable skill in DevOps and software engineering.\n",
    "\n",
    "By implementing this DockerComposeManager now, we're not just preparing for future needs; we're establishing good practices from the start. It encourages thinking about operations and development as interconnected aspects of the project, which is a core principle in modern DevOps practices.\n",
    "\n",
    "As we continue to develop PandorasLock, this class will likely evolve. We might add methods for scaling services, running database migrations, or performing health checks. By having this foundation in place early, we make it easier to implement these features consistently across the project.\n",
    "\n",
    "Let's create this class in our project structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Construct the path to the src/utils directory\n",
    "utils_dir = os.path.join(current_dir, '..', 'src', 'utils')\n",
    "\n",
    "# Ensure the utils directory exists\n",
    "os.makedirs(utils_dir, exist_ok=True)\n",
    "\n",
    "# Construct the full path for the DockerComposeManager.py file\n",
    "docker_compose_manager_path = os.path.join(utils_dir, 'DockerComposeManager.py')\n",
    "\n",
    "# Content of the DockerComposeManager.py file\n",
    "docker_compose_manager_content = \"\"\"\n",
    "import subprocess\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class DockerComposeManager:\n",
    "    def __init__(self, compose_file_path):\n",
    "        self.compose_file_path = os.path.abspath(compose_file_path)\n",
    "        load_dotenv(dotenv_path=os.path.join(os.path.dirname(self.compose_file_path), '.env'))\n",
    "\n",
    "    def run_command(self, command):\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                f\"docker compose -f {self.compose_file_path} {command}\",\n",
    "                shell=True, check=True, capture_output=True, text=True\n",
    "            )\n",
    "            print(result.stdout)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Error executing command: {e}\")\n",
    "            print(e.stderr)\n",
    "\n",
    "    def start_containers(self):\n",
    "        self.run_command(\"up -d\")\n",
    "\n",
    "    def stop_containers(self):\n",
    "        self.run_command(\"down\")\n",
    "\n",
    "    def show_container_status(self):\n",
    "        self.run_command(\"ps\")\n",
    "\"\"\"\n",
    "\n",
    "# Write the content to the DockerComposeManager.py file\n",
    "with open(docker_compose_manager_path, 'w') as f:\n",
    "    f.write(docker_compose_manager_content)\n",
    "\n",
    "print(f\"DockerComposeManager.py file created at: {docker_compose_manager_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Setup Directory Structure and Launch Docker Containers\n",
    "\n",
    "In this final section, we'll set up our directory structure for persistent databases and then use our newly created tools to launch the Docker containers.\n",
    "\n",
    "First, let's create the necessary directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import psycopg2\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Get the project root directory and add it to the Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.utils.DockerComposeManager import DockerComposeManager\n",
    "from src.utils.config_utils import Config\n",
    "\n",
    "def create_directories(config):\n",
    "    # Create a directory for database persistence\n",
    "    db_dir = os.path.join(project_root, 'db_data')\n",
    "    os.makedirs(db_dir, exist_ok=True)\n",
    "\n",
    "    # Create subdirectories for each database\n",
    "    postgres_dir = os.path.join(db_dir, 'postgres')\n",
    "    neo4j_dir = os.path.join(db_dir, 'neo4j')\n",
    "\n",
    "    os.makedirs(postgres_dir, exist_ok=True)\n",
    "    os.makedirs(neo4j_dir, exist_ok=True)\n",
    "\n",
    "    print(f\"Created database directories:\")\n",
    "    print(f\"PostgreSQL: {postgres_dir}\")\n",
    "    print(f\"Neo4j: {neo4j_dir}\")\n",
    "\n",
    "def verify_env_variables(config):\n",
    "    print(\"\\nVerifying environment variables:\")\n",
    "    print(f\"POSTGRES_DB: {config.POSTGRES_DB}\")\n",
    "    print(f\"POSTGRES_USER: {config.POSTGRES_USER}\")\n",
    "    print(f\"POSTGRES_HOST: {config.POSTGRES_HOST}\")\n",
    "    print(f\"POSTGRES_PORT: {config.POSTGRES_PORT}\")\n",
    "    print(f\"NEO4J_HOST: {config.NEO4J_HOST}\")\n",
    "    print(f\"NEO4J_HTTP_PORT: {config.NEO4J_HTTP_PORT}\")\n",
    "    print(f\"NEO4J_BOLT_PORT: {config.NEO4J_BOLT_PORT}\")\n",
    "    print(f\"DOCKER_NETWORK_NAME: {config.DOCKER_NETWORK_NAME}\")\n",
    "\n",
    "def wait_for_postgres(config, max_attempts=5, delay=5):\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            conn = psycopg2.connect(\n",
    "                dbname=config.POSTGRES_DB,\n",
    "                user=config.POSTGRES_USER,\n",
    "                password=config.POSTGRES_PASSWORD,\n",
    "                host=config.POSTGRES_HOST,\n",
    "                port=config.POSTGRES_PORT\n",
    "            )\n",
    "            conn.close()\n",
    "            print(f\"Successfully connected to PostgreSQL on port {config.POSTGRES_PORT}\")\n",
    "            return True\n",
    "        except psycopg2.OperationalError as e:\n",
    "            print(f\"Attempt {attempt + 1}/{max_attempts}: PostgreSQL is not ready yet. Error: {e}\")\n",
    "            time.sleep(delay)\n",
    "    return False\n",
    "\n",
    "def wait_for_neo4j(config, max_attempts=5, delay=5):\n",
    "    for attempt in range(max_attempts):\n",
    "        try:\n",
    "            print(f\"Debug: Attempting to connect to Neo4j (Attempt {attempt + 1})\")\n",
    "            print(f\"Debug: NEO4J_AUTH = {config.NEO4J_AUTH}\")\n",
    "            print(f\"Debug: NEO4J_HOST = {config.NEO4J_HOST}\")\n",
    "            print(f\"Debug: NEO4J_BOLT_PORT = {config.NEO4J_BOLT_PORT}\")\n",
    "            \n",
    "            neo4j_params = config.get_neo4j_connection_params()\n",
    "            print(f\"Debug: Neo4j connection params: {neo4j_params}\")\n",
    "            \n",
    "            driver = GraphDatabase.driver(\n",
    "                neo4j_params['uri'],\n",
    "                auth=neo4j_params['auth']\n",
    "            )\n",
    "            with driver.session() as session:\n",
    "                result = session.run(\"RETURN 1 AS x\")\n",
    "                assert result.single()['x'] == 1\n",
    "            driver.close()\n",
    "            print(f\"Successfully connected to Neo4j on port {config.NEO4J_BOLT_PORT}\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {attempt + 1}/{max_attempts}: Neo4j is not ready yet. Error: {e}\")\n",
    "            print(f\"Error type: {type(e)}\")\n",
    "            print(f\"Error details: {str(e)}\")\n",
    "            time.sleep(delay)\n",
    "    return False\n",
    "\n",
    "def verify_database_connections(config):\n",
    "    postgres_ready = wait_for_postgres(config)\n",
    "    neo4j_ready = wait_for_neo4j(config)\n",
    "\n",
    "    if postgres_ready and neo4j_ready:\n",
    "        print(\"\\nAll database connections are successful!\")\n",
    "    else:\n",
    "        print(\"\\nSome database connections failed. Please check your configuration and container logs.\")\n",
    "\n",
    "def main():\n",
    "    # Load configuration\n",
    "    config = Config()\n",
    "\n",
    "    # Create necessary directories\n",
    "    create_directories(config)\n",
    "\n",
    "    # Verify environment variables\n",
    "    verify_env_variables(config)\n",
    "\n",
    "    # Create an instance of DockerComposeManager\n",
    "    docker_compose_path = os.path.join(project_root, 'config', 'docker-compose.yml')\n",
    "    docker_manager = DockerComposeManager(docker_compose_path)\n",
    "\n",
    "    # Start the containers\n",
    "    print(\"\\nStarting Docker containers...\")\n",
    "    docker_manager.start_containers()\n",
    "\n",
    "    # Wait for containers to fully start\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Check the status of the containers\n",
    "    print(\"\\nChecking container status:\")\n",
    "    docker_manager.show_container_status()\n",
    "\n",
    "    # Verify database connections\n",
    "    verify_database_connections(config)\n",
    "\n",
    "    # Print connection information\n",
    "    print(\"\\nConnection Information:\")\n",
    "    print(f\"PostgreSQL: {config.POSTGRES_HOST}:{config.POSTGRES_PORT}\")\n",
    "    print(f\"Neo4j (HTTP): {config.NEO4J_HOST}:{config.NEO4J_HTTP_PORT}\")\n",
    "    print(f\"Neo4j (Bolt): {config.NEO4J_HOST}:{config.NEO4J_BOLT_PORT}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've successfully set up a robust database environment for our RAG (Retrieval-Augmented Generation) system. Here's a summary of our key accomplishments:\n",
    "\n",
    "1. **Database Infrastructure**: We've established a Docker-based setup with two powerful databases:\n",
    "   - PostgreSQL with pgvector extension for efficient vector storage and similarity searches.\n",
    "   - Neo4j for graph-based data representation and querying.\n",
    "\n",
    "2. **Configuration Management**: We implemented a flexible `Config` class that:\n",
    "   - Loads environment variables from a `.env` file.\n",
    "   - Provides easy access to configuration settings throughout our project.\n",
    "   - Handles both PostgreSQL and Neo4j configurations.\n",
    "\n",
    "3. **Docker Environment**: We created a `docker-compose.yml` file that:\n",
    "   - Sets up our PostgreSQL and Neo4j containers.\n",
    "   - Uses environment variables for flexible configuration.\n",
    "   - Establishes persistent storage for our databases.\n",
    "\n",
    "4. **Automated Setup and Verification**: We developed a Python script that:\n",
    "   - Creates necessary directories for database persistence.\n",
    "   - Launches Docker containers using our DockerComposeManager.\n",
    "   - Verifies successful connections to both PostgreSQL and Neo4j.\n",
    "\n",
    "5. **Troubleshooting and Debugging**: Throughout this process, we encountered and resolved several challenges:\n",
    "   - Corrected port conflicts for PostgreSQL.\n",
    "   - Addressed issues with Neo4j authentication settings.\n",
    "   - Implemented detailed error reporting and debugging output.\n",
    "\n",
    "### Accessing the Neo4j Web Interface\n",
    "\n",
    "As part of our setup, we've enabled access to Neo4j's powerful web interface, Neo4j Browser. Here's how you can connect to it:\n",
    "\n",
    "1. Open your web browser and navigate to `http://localhost:7474`.\n",
    "2. You'll be presented with a login screen.\n",
    "3. Enter the following credentials:\n",
    "   - Username: `neo4j` (or the username you set in your .env file)\n",
    "   - Password: [The password you set in your .env file]\n",
    "4. Once logged in, you'll have access to the Neo4j Browser interface where you can:\n",
    "   - Run Cypher queries directly in the browser.\n",
    "   - Visualize your graph data.\n",
    "   - Explore Neo4j's built-in documentation and tutorials.\n",
    "\n",
    "This interface is an invaluable tool for interacting with your graph database, allowing you to easily query, visualize, and manipulate your data as you develop your RAG system.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In our next notebook, we will focus on integrating Ollama, a tool for running large language models, with our existing database setup. We'll cover:\n",
    "\n",
    "1. Setting up an Ollama container and connecting it to our Docker network.\n",
    "2. Establishing connections between Ollama and our PostgreSQL and Neo4j databases.\n",
    "3. Implementing basic data flow between Ollama and our databases.\n",
    "4. Testing the integrated system with simple RAG operations.\n",
    "\n",
    "This upcoming integration will bring us closer to a fully functional RAG system, combining the power of large language models with our sophisticated database backend.\n",
    "\n",
    "This database setup, including the accessible Neo4j web interface, forms the foundation of our RAG system, providing us with the capability to store, query, and visualize both vector embeddings and graph-structured data efficiently.\n",
    "\n",
    "By methodically building our system component by component, we're creating a robust, flexible, and powerful tool for advanced natural language processing tasks. The challenges we've overcome in this notebook have not only resulted in a working database setup but have also deepened our understanding of configuration management, Docker containerization, and database connectivity in a complex system."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragtools",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
